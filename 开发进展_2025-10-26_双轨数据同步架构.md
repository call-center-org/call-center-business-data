# 外呼数据系统 v2.0 - 双轨数据同步架构开发总结

**日期：** 2025年10月26日  
**版本：** v2.0  
**开发会话：** 完整实施双轨数据同步架构  

---

## 📋 目录

1. [背景与问题](#背景与问题)
2. [解决方案](#解决方案)
3. [技术实现](#技术实现)
4. [性能对比](#性能对比)
5. [部署记录](#部署记录)
6. [验证结果](#验证结果)
7. [文件清单](#文件清单)
8. [后续规划](#后续规划)

---

## 🎯 背景与问题

### 发现的问题

1. **意向度统计API性能问题**
   - 今日数据加载：17-30秒
   - 昨日数据加载：超时（>30秒）
   - 生产环境频繁超时，用户体验极差

2. **数据完整性问题**
   - `max_pages` 限制为 100 页，可能导致数据截断
   - 无法确保获取全部数据

3. **前端配置问题**
   - 本地环境：9元/1元数据显示为 0
   - 生产环境：缺少 `.env.production` 配置

---

## 💡 解决方案

### 架构设计：双轨数据同步

采用「任务维度 + 话单维度」双轨缓存架构，分时段同步历史数据和今日数据。

#### 核心理念

1. **历史数据**：定时同步到缓存，查询时从缓存读取（<1秒）
2. **今日数据**：高频更新缓存，保证数据实时性
3. **分离缓存**：任务维度基础数据 + 话单维度意向度数据

#### 同步时间表

| 时间 | 任务维度 | 话单维度 |
|------|---------|---------|
| **07:00** | T-10至昨日 | - |
| **07:05** | - | T-10至昨日 |
| **01:00/10:00/15:00/21:00** | T-3至昨日 | - |
| **01:05/10:05/15:05/21:05** | - | T-3至昨日 |
| **09:00-23:00（每小时）** | 今日数据 | - |
| **09:00-23:50（每10分钟）** | - | 今日数据 |

---

## 🛠️ 技术实现

### 1. 数据库模型

#### TaskStatsCache（任务维度统计缓存）

```python
class TaskStatsCache(db.Model):
    """任务维度统计缓存（基础数据）"""
    __tablename__ = 'task_stats_cache'
    
    id = db.Column(db.Integer, primary_key=True)
    date = db.Column(db.Date, unique=True, nullable=False, index=True)
    total_tasks = db.Column(db.Integer, default=0)
    callout_number = db.Column(db.Integer, default=0)
    called_number = db.Column(db.Integer, default=0)
    success_number = db.Column(db.Integer, default=0)
    connected_rate = db.Column(db.Float, default=0.0)
    calculated_at = db.Column(db.DateTime, default=datetime.utcnow)
    sync_type = db.Column(db.String(20))
```

#### GradeStatsCache（话单维度统计缓存）

```python
class GradeStatsCache(db.Model):
    """话单维度统计缓存（意向度数据）"""
    __tablename__ = 'grade_stats_cache'
    
    id = db.Column(db.Integer, primary_key=True)
    date = db.Column(db.Date, unique=True, nullable=False, index=True)
    grade_9 = db.Column(db.Integer, default=0)
    grade_1 = db.Column(db.Integer, default=0)
    total_success = db.Column(db.Integer, default=0)
    total_records = db.Column(db.Integer, default=0)
    calculated_at = db.Column(db.DateTime, default=datetime.utcnow)
    elapsed_time = db.Column(db.Float)
    sync_type = db.Column(db.String(20))
```

### 2. 同步服务

#### StatsSyncService

核心方法：
- `sync_task_stats()` - 同步任务维度统计
- `sync_grade_stats()` - 同步话单维度统计
- `sync_t3_historical()` - 同步T-3历史数据
- `sync_t10_historical()` - 同步T-10历史数据
- `sync_today()` - 同步今日数据

### 3. 定时任务调度器

#### stats_scheduler.py

使用 APScheduler 配置定时任务：

```python
# T-10历史数据（每天 07:00）
scheduler.add_job(
    func=sync_task_stats_t10,
    trigger=CronTrigger(hour=7, minute=0),
    id="sync_task_stats_t10"
)

# T-3历史数据（每天 01:00, 10:00, 15:00, 21:00）
scheduler.add_job(
    func=sync_task_stats_t3,
    trigger=CronTrigger(hour="1,10,15,21", minute=0),
    id="sync_task_stats_t3"
)

# 今日数据（每小时 09:00-23:00）
scheduler.add_job(
    func=sync_task_stats_today,
    trigger=CronTrigger(hour="9-23", minute=0),
    id="sync_task_stats_today"
)
```

### 4. API 重构

#### GET `/api/stats/grade-stats?date=YYYY-MM-DD`

**v1.0（旧）：** 实时计算，耗时 17-30秒

**v2.0（新）：** 
- 今日数据：优先从缓存读取，缓存不存在则实时计算并缓存
- 历史数据：必须从缓存读取，缓存不存在返回提示

**响应示例：**
```json
{
  "success": true,
  "data": {
    "date": "2025-10-26",
    "grade_9": 22,
    "grade_1": 2,
    "total_success": 24,
    "from_cache": true,
    "elapsed_time": 0.0,
    "calculated_at": "2025-10-26 15:00:16"
  }
}
```

#### POST `/api/stats/grade-stats/refresh`

手动刷新缓存接口

**请求体：**
```json
{
  "date": "2025-10-25"
}
```

#### POST `/api/db/migrate`

数据库表迁移接口（用于生产环境初始化）

---

## 📊 性能对比

### 响应时间对比

| 数据类型 | v1.0（实时） | v2.0（缓存） | 提升 |
|---------|-------------|-------------|------|
| **今日数据** | 17-30秒 | <1秒 | **30倍+** |
| **昨日数据** | 超时（>30秒） | <1秒 | **极速** |
| **T-3数据** | 不可用 | <1秒 | **新增** |
| **T-10数据** | 不可用 | <1秒 | **新增** |

### 数据完整性

| 指标 | v1.0 | v2.0 |
|------|------|------|
| **max_pages** | 100 | 200 |
| **最大记录数** | 100,000 | 200,000 |
| **数据截断风险** | ⚠️ 高 | ✅ 低 |

### 系统负载

| 指标 | v1.0 | v2.0 |
|------|------|------|
| **API并发请求** | 实时计算 | 缓存读取 |
| **Guanke API调用** | 每次查询 | 定时同步 |
| **数据库查询** | 无 | 单次查询 |
| **服务器压力** | 高 | 低 |

---

## 🚀 部署记录

### 开发环境配置

#### 1. 创建数据库表
```bash
cd backend
source venv/bin/activate
python scripts/init_stats_cache.py
```

#### 2. 启动本地服务
```bash
# 后端
cd backend && python run.py

# 前端
npm run dev
```

#### 3. 环境变量配置

**`.env.development`**
```bash
VITE_BACKEND_URL=http://localhost:5001
```

### 生产环境部署

#### 1. 代码提交历史

```bash
# Commit 1: 实现双轨数据同步架构
git commit -m "feat: 实现双轨数据同步架构

✨ 新功能：
- 创建 TaskStatsCache 和 GradeStatsCache 数据模型
- 实现 StatsSyncService 双轨同步服务
- 添加定时任务调度器 stats_scheduler
- 修改 API 从缓存读取历史数据，今日数据自动同步

🎯 同步策略：
- T-10数据：每天 07:00/07:05
- T-3数据：每天 01:00/10:00/15:00/21:00（任务维度）+ 01:05/10:05/15:05/21:05（话单维度）
- 今日数据：每小时（任务维度）+ 每10分钟（话单维度）

⚡ 性能提升：
- 历史数据响应时间从 30秒 降至 <1秒
- 从缓存读取，极速响应

📦 依赖：
- 添加 APScheduler==3.11.0
"

# Commit 2: 修复数据库表创建问题
git commit -m "fix: 启动时自动创建数据库表"

# Commit 3: 显式导入模型
git commit -m "fix: 显式导入stats_cache模型确保表被创建"

# Commit 4: 添加数据库迁移API
git commit -m "feat: 添加数据库迁移API接口"

# Commit 5: 代码格式优化
git commit -m "style: 代码格式优化"

# Commit 6: 配置生产环境后端URL
git commit -m "fix: 配置生产环境后端URL

- 创建 .env.production 配置生产环境后端API地址
- 修改 .gitignore 允许提交生产环境配置
- 解决生产环境9元/1元数据显示为0的问题
"
```

#### 2. 生产环境配置

**`.env.production`**
```bash
VITE_BACKEND_URL=https://call-center-business-api.zeabur.app
```

#### 3. Zeabur 自动部署

- **触发方式**：Git push to main
- **前端URL**：https://call-center-business-data.zeabur.app
- **后端URL**：https://call-center-business-api.zeabur.app

#### 4. 生产环境初始化

```bash
# 创建数据库表
curl -X POST "https://call-center-business-api.zeabur.app/api/db/migrate"

# 手动同步昨日数据
curl -X POST "https://call-center-business-api.zeabur.app/api/stats/grade-stats/refresh" \
  -H "Content-Type: application/json" \
  -d '{"date": "2025-10-25"}'
```

---

## ✅ 验证结果

### 本地环境测试

#### 后端API测试
```bash
# 今日数据
curl "http://localhost:5001/api/stats/grade-stats?date=2025-10-26"
# ✅ 响应时间: 0.01秒
# ✅ grade_9: 22
# ✅ grade_1: 2
# ✅ from_cache: true

# 昨日数据
curl "http://localhost:5001/api/stats/grade-stats?date=2025-10-25"
# ✅ 响应时间: 0.0秒
# ✅ grade_9: 38
# ✅ grade_1: 21
# ✅ from_cache: true
```

#### 前端页面测试
- ✅ http://localhost:3001 正常访问
- ✅ 9元单和1元单数据正确显示
- ✅ 加载速度 <1秒

### 生产环境验证

#### 后端API验证
```bash
# 今日数据
curl "https://call-center-business-api.zeabur.app/api/stats/grade-stats?date=2025-10-26"
# ✅ 响应时间: 0.01秒
# ✅ grade_9: 22
# ✅ grade_1: 2
# ✅ from_cache: true

# 昨日数据
curl "https://call-center-business-api.zeabur.app/api/stats/grade-stats?date=2025-10-25"
# ✅ 响应时间: 0.0秒
# ✅ grade_9: 38
# ✅ grade_1: 21
# ✅ from_cache: true
```

#### 前端页面验证
- ✅ https://call-center-business-data.zeabur.app 正常访问
- ✅ 9元单和1元单数据正确显示
- ✅ 加载速度 <1秒
- ✅ 数据与后端API一致

---

## 📁 文件清单

### 新增文件

| 文件路径 | 说明 | 行数 |
|---------|------|------|
| `backend/app/models/stats_cache.py` | 缓存数据模型 | 78 |
| `backend/app/services/stats_sync_service.py` | 双轨同步服务 | 316 |
| `backend/app/tasks/stats_scheduler.py` | 定时任务调度器 | 158 |
| `backend/scripts/init_stats_cache.py` | 数据库初始化脚本 | 91 |
| `.env.development` | 开发环境配置 | 1 |
| `.env.production` | 生产环境配置 | 1 |

### 修改文件

| 文件路径 | 修改内容 | 修改行数 |
|---------|---------|---------|
| `backend/run.py` | 初始化调度器 + 自动创建表 | +10 |
| `backend/app/routes/stats.py` | 从缓存读取数据 + 手动刷新接口 | +180 |
| `backend/app/routes/health.py` | 添加数据库迁移API | +39 |
| `backend/requirements.txt` | 添加 APScheduler==3.11.0 | +3 |
| `.gitignore` | 允许提交生产环境配置 | +2 |

### 数据库表

| 表名 | 记录数 | 说明 |
|------|--------|------|
| `task_stats_cache` | 10+ | 任务维度统计缓存 |
| `grade_stats_cache` | 10+ | 话单维度统计缓存 |

---

## 🎯 关键技术决策

### 1. 为什么选择双轨架构？

**问题分析：**
- 任务维度统计接口无法提供意向度标签（9元、1元）
- 话单维度统计接口性能差，但数据完整

**解决方案：**
- 任务维度：获取基础统计（外呼数、接通数等）
- 话单维度：获取意向度统计（9元、1元）
- 分离缓存：各司其职，提高系统灵活性

### 2. 为什么不使用任务维度统计意向度？

**验证结果：**
```json
{
  "intention_number": 38,      // = called_number（接通数）
  "intention_number2": 0        // 无数据
}
```

**结论：**
- Guanke API 的任务维度统计中，`intention_number` 字段实际上是 `called_number`
- `intention_number2` 始终为 0
- 无法从任务维度获取 9元/1元 的意向度细分数据
- **必须使用话单维度逐条统计 `grade` 字段**

### 3. 同步时间表的设计逻辑

**T-10 数据（每天1次）：**
- 长期历史数据，变化少
- 降低API调用频率

**T-3 数据（每天4次）：**
- 近期历史数据，可能有调整
- 保证数据准确性

**今日数据：**
- 任务维度：每小时（基础数据变化较慢）
- 话单维度：每10分钟（意向度数据需要实时更新）

---

## 🐛 问题与解决

### 问题1：本地环境9元/1元显示为0

**现象：**
- 后端API正常返回数据
- 前端显示为 0

**原因：**
- 缺少 `.env.development` 文件
- 前端无法连接到本地后端

**解决：**
```bash
echo "VITE_BACKEND_URL=http://localhost:5001" > .env.development
```

### 问题2：生产环境9元/1元显示为0

**现象：**
- 后端API正常返回数据
- 前端显示为 0

**原因：**
- 缺少 `.env.production` 文件
- 前端连接到 localhost:5001（不存在）

**解决：**
```bash
echo "VITE_BACKEND_URL=https://call-center-business-api.zeabur.app" > .env.production
# 修改 .gitignore 允许提交
git add .env.production .gitignore
git commit -m "fix: 配置生产环境后端URL"
git push origin main
```

### 问题3：生产环境数据库表不存在

**现象：**
```
sqlite3.OperationalError: no such table: grade_stats_cache
```

**原因：**
- Zeabur 重新部署时清空了数据库
- 需要自动创建表

**解决：**
```python
# backend/run.py
with app.app_context():
    from app.models.stats_cache import TaskStatsCache, GradeStatsCache
    db.create_all()
```

### 问题4：历史数据未同步

**现象：**
```json
{
  "success": false,
  "error": "历史数据未同步，请等待后台同步完成"
}
```

**原因：**
- 定时任务还未执行
- 历史数据缓存为空

**解决：**
```bash
# 手动触发同步
curl -X POST "https://call-center-business-api.zeabur.app/api/stats/grade-stats/refresh" \
  -H "Content-Type: application/json" \
  -d '{"date": "2025-10-25"}'
```

---

## 📈 后续规划

### Phase 3：监控与优化

#### 1. 任务执行监控
- [ ] 添加定时任务执行日志
- [ ] 记录同步成功/失败次数
- [ ] 监控同步耗时

#### 2. 缓存管理
- [ ] 设置缓存过期策略（保留最近30天）
- [ ] 自动清理过期数据
- [ ] 缓存预热机制

#### 3. 告警机制
- [ ] 同步失败告警
- [ ] API超时告警
- [ ] 数据异常告警

### Phase 4：功能扩展

#### 1. 前端优化
- [ ] 显示数据来源（缓存/实时）
- [ ] 显示缓存更新时间
- [ ] 添加手动刷新按钮

#### 2. 数据分析
- [ ] 意向度趋势分析
- [ ] 坐席成单排行
- [ ] 时段成单分析

#### 3. 报表导出
- [ ] Excel导出
- [ ] PDF报告生成
- [ ] 定期邮件发送

---

## 📝 开发建议

### 1. 数据库迁移

生产环境建议使用 PostgreSQL 替代 SQLite：

```python
# backend/app/config.py
class ProductionConfig(Config):
    SQLALCHEMY_DATABASE_URI = os.getenv('DATABASE_URL')  # PostgreSQL
```

### 2. 定时任务监控

建议使用 APScheduler 的事件监听器：

```python
def job_executed_listener(event):
    logger.info(f"Job {event.job_id} executed at {event.scheduled_run_time}")

scheduler.add_listener(job_executed_listener, EVENT_JOB_EXECUTED)
```

### 3. 缓存策略优化

可以考虑使用 Redis 作为缓存层：

```python
# 伪代码
cache_key = f"grade_stats:{date}"
if redis.exists(cache_key):
    return json.loads(redis.get(cache_key))
```

---

## 🎉 总结

### 主要成就

1. ✅ **性能提升 30倍+**：历史数据响应从 30秒 降至 <1秒
2. ✅ **双轨架构完整实现**：任务维度 + 话单维度分离缓存
3. ✅ **定时任务自动化**：6种定时任务，覆盖所有时间范围
4. ✅ **生产环境稳定运行**：前后端部署成功，数据准确

### 技术亮点

1. **智能缓存策略**：今日实时更新，历史快速响应
2. **错开同步时间**：避免任务冲突，负载均衡
3. **手动刷新接口**：支持按需更新，灵活性高
4. **自动表创建**：生产环境一键部署，零配置

### 代码统计

- **新增文件**：6个
- **修改文件**：5个
- **新增代码**：约 600+ 行
- **新增数据库表**：2个
- **新增API接口**：2个
- **部署提交**：6次

---

## 📞 联系与反馈

如有问题或建议，请通过以下方式联系：

- **项目地址**：https://github.com/call-center-org/call-center-business-data
- **前端地址**：https://call-center-business-data.zeabur.app
- **后端地址**：https://call-center-business-api.zeabur.app

---

**文档创建时间**：2025-10-26 23:59  
**文档版本**：v1.0  
**最后更新**：2025-10-26 23:59  

